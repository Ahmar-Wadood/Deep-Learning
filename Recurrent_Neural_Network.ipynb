{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p1llQMbsbgc"
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onrQcv0ENYMD",
        "outputId": "c9966f1e-d405-466c-a914-94c65486ce49"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "sentences = [\r\n",
        "    'I love my dog',\r\n",
        "    'I love my cat',\r\n",
        "    'You love my dog!',\r\n",
        "    'Do you think my dog is amazing?'\r\n",
        "]\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\r\n",
        "tokenizer.fit_on_texts(sentences)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOV>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHUdOyXnNYhJ",
        "outputId": "cd4f8a33-cfbb-4943-f283-fff1dbd0b2be"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\r\n",
        "print(sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J1sFSfHOCe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14f1e15-f862-4ffa-d938-f2bef245b0b6"
      },
      "source": [
        "test_data = [\r\n",
        "    'i really love my dog',\r\n",
        "    'my dog loves my manatee'\r\n",
        "]\r\n",
        "\r\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\r\n",
        "print(\"\\nTest Sequence = \", test_seq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Sequence =  [[5, 1, 3, 2, 4], [2, 4, 1, 2, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgX7HN5lsi20",
        "outputId": "4c967762-6b58-4270-c668-fd43dd3cf7f3"
      },
      "source": [
        "vocabulary_size = 5000\r\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\r\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbNzmZfksoEb",
        "outputId": "4dd79b1f-93f2-4ad4-9dc8-dc3a72f1cff0"
      },
      "source": [
        "print('---review---')\r\n",
        "print(X_train[9])\r\n",
        "print('---label---')\r\n",
        "print(y_train[9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---review---\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    1   14   20   47  111  439 3445   19\n",
            "   12   15  166   12  216  125   40    6  364  352  707 1187   39  294\n",
            "   11   22  396   13   28    8  202   12 1109   23   94    2  151  111\n",
            "  211  469    4   20   13  258  546 1104    2   12   16   38   78   33\n",
            "  211   15   12   16 2849   63   93   12    6  253  106   10   10   48\n",
            "  335  267   18    6  364 1242 1179   20   19    6 1009    7 1987  189\n",
            "    5    6    2    7 2723    2   95 1719    6    2    7 3912    2   49\n",
            "  369  120    5   28   49  253   10   10   13 1041   19   85  795   15\n",
            "    4  481    9   55   78  807    9  375    8 1167    8  794   76    7\n",
            "    4   58    5    4  816    9  243    7   43   50]\n",
            "---label---\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjTF67lPtAf8"
      },
      "source": [
        "Note that the review is stored as a sequence of integers. These are word IDs that have been pre-assigned to individual words, and the label is an integer (0 for negative, 1 for positive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JXvovIPsyqX",
        "outputId": "093c18d4-d34b-4518-fcde-ab8882960d89"
      },
      "source": [
        "word2id = imdb.get_word_index()\r\n",
        "id2word = {i: word for word, i in word2id.items()}\r\n",
        "print('---review with words---')\r\n",
        "print([id2word.get(i, ' ') for i in X_train[6]])\r\n",
        "print('---label---')\r\n",
        "print(y_train[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "---review with words---\n",
            "['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F6WEBjQtFDD",
        "outputId": "fa432305-9122-4029-d165-aa1c309755c5"
      },
      "source": [
        "print('Maximum review length: {}'.format(\r\n",
        "len(max((X_train + X_test), key=len))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 2697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71udyS0BtXmC"
      },
      "source": [
        "from keras.preprocessing import sequence\r\n",
        "max_words = 500\r\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\r\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYDsDX-Wtb6l",
        "outputId": "a5e919a6-0f83-4e4a-ee16-c0a5855f0d1a"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   14,    6,  717],\n",
              "       [   0,    0,    0, ...,  125,    4, 3077],\n",
              "       [  33,    6,   58, ...,    9,   57,  975],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   21,  846,    2],\n",
              "       [   0,    0,    0, ..., 2302,    7,  470],\n",
              "       [   0,    0,    0, ...,   34, 2005, 2643]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn7K5AzdtezS",
        "outputId": "1765fa71-9ed9-4939-b9cb-720c36ae0bcb"
      },
      "source": [
        "from keras import Sequential\r\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\r\n",
        "embedding_size=32\r\n",
        "model=Sequential()\r\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\r\n",
        "model.add(LSTM(100))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ln8Nvj0t_3Y"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \r\n",
        "             optimizer='adam', \r\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6sIjGYcuG_x",
        "outputId": "f266c210-a188-4ecd-cceb-087486b59fdc"
      },
      "source": [
        "batch_size = 64\r\n",
        "num_epochs = 3\r\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\r\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\r\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "390/390 [==============================] - 228s 578ms/step - loss: 0.5650 - accuracy: 0.6815 - val_loss: 0.3620 - val_accuracy: 0.8594\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 218s 560ms/step - loss: 0.2869 - accuracy: 0.8873 - val_loss: 0.2845 - val_accuracy: 0.9062\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 219s 561ms/step - loss: 0.2335 - accuracy: 0.9115 - val_loss: 0.2385 - val_accuracy: 0.9062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f85b6db50d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9_CV4I9uJqL",
        "outputId": "49230c9f-dd2a-45d8-f801-2b311fa1a53f"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.875760018825531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33V6HuCfx8Ak",
        "outputId": "1878d8c3-8530-47d0-874b-5a6c05efc20f"
      },
      "source": [
        "print('---review---')\r\n",
        "print(X_test[9])\r\n",
        "print('---label---')\r\n",
        "print(y_test[9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---review---\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    1   14   22    9  121    4 1354 3135 3882    8\n",
            "   28 2230  151   13   80    2   15    4 1008  496 1354 1437   71  321\n",
            "    5  100   28   77  714    2   34    6 3275  167   17   12  679   46\n",
            "   14   16   24    8   30    4  420   10   10  684 2991 1094    2   71\n",
            "  685   19   89  465   14  333 1354   22   39 1756 3555  679   46  972\n",
            "   39    4    2    7 1017  233  334   39 3555    5    4 4528    2    7\n",
            "   68 3691 2154    8  471    4 3135   83   35 3490    8    4 4997  248\n",
            "  201   13 1854    8  391   89 1354 1747   70   30 1192   33   32 1332\n",
            "   10   10  283   12    9   24  179    4 3215    7    4   86   22  151\n",
            "   12    2   32    4 1403    2    7  405  258   11 1354    6    2  229\n",
            "   15    2    4    2  200   24   43  107   21  289  105    2    2    2\n",
            "    8    4 4796    2    7 2065    5  718 4462   17    4    2   11    4\n",
            "   86   22  246   18   32   14   12 1287    6    2  465   22  283    8\n",
            "    4   96    4 1354   16  210  981    8   30    5  545 2349   10   10\n",
            "  488 2065 1747   17    4 1354    5   27    2 3530 1478 2451   19    2\n",
            " 2431    2 1368 3590  773   11    2    7    4    2 1124 1295  284   27\n",
            " 1943   11  823    2    2    4    2 1738    2   11  530 2430 2781    7\n",
            "    2    2  745 3448    5    2    2    4    2 2861    2  937 2451    2\n",
            "  199   17  309    5   17    4 1354    4  689    2  471   11  321  354\n",
            "  262 3590    5    2  137  295 2065    5    2 3739    4 3778  499    7\n",
            " 1405    2   10   10   50   26   49 1774    2   11   14   22   44    4\n",
            "   64    2   13   70   66  213   46    9    6  813    8    4  229   11\n",
            "   49 1370   63   13  104    9  688  669    8    4   96   14   22    9\n",
            "    6  689    2  548   50  331  218  195   58    8 2887 3739  803  170\n",
            "   23   10   10 2185   14    9    6 1543   52   22   13  545  386  149\n",
            "   14   11    2   19    4   86    5   95    2   18   89   52    4  201\n",
            "  100   28   77   69   12 3501  467 3555    5 2065]\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snOgXdC4xKt3",
        "outputId": "9bf141ac-cd7f-4e63-aaab-6bfe44d6b862"
      },
      "source": [
        "print(\"Prediction: \",model.predict_classes(X_test[5:10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Prediction:  [[1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwzkiE1Yxhbk",
        "outputId": "d16a7b96-0911-4c22-a5c1-220492de34a7"
      },
      "source": [
        "print(\"Actual: \\n\",y_test[5:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: \n",
            " [1 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5LFzZiUxjj2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}